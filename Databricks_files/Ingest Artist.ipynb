{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ac4131a-4e55-4538-babc-9d8b9719dee6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime  # Import the datetime module\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad0e537-58b2-4ce7-92c8-66e11fe00d67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer BQCjFJwvBvJKFLKhSTD2CDal8xJdJA8XcRpp96tck0Rduavh2bdZNoQBwbCy_VPx2_eY36AVAHBTujaAcqkpSukYAFPWdyiXWHZUPmPlkZRLm37WVww'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|            ArtistId|\n+--------------------+\n|0AmBT7fJDVHS4Bshg...|\n|0fhunuOz2OuOEr3YK...|\n|0GOx72r5AAEKRGQFn...|\n|0hd66OEzb2gfUd7dr...|\n|0lGQjr3FTxAwGLlpc...|\n|0LyfQWJT6nXafLPZq...|\n|0oSGxfWSnnOXhD2fK...|\n|0qS0rxCY4YfrUx9GC...|\n|0qT79UgT5tY4yudH9...|\n|0TF2NxkJZPQoX1H53...|\n|0vn7UBvSQECKJm281...|\n|0w3PsroIezW7uRTNx...|\n|0weZCKF1LhfyKpvcz...|\n|0wv5i0ds2z040yx7o...|\n|13M1OXRslYiaRoeaU...|\n|151w10AZKmL4a6iPw...|\n|1A9o3Ljt67pFZ89Yt...|\n|1aXtuiimQwgW8Xqzt...|\n|1bRcW8SnU3AKrhzxn...|\n|1dfeR4HaWDbWqFHLk...|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#token = \"\"\n",
    "token = dbutils.widgets.get('token')\n",
    "artists_id_index = 0\n",
    "headers = {\"Authorization\": token}\n",
    "display(headers) \n",
    "\n",
    "# Assuming you have a CSV file uploaded to Databricks File System (DBFS)\n",
    "csv_file_path = \"/mnt/raw/artist_data/ds_artists_ids_raw.csv\"\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True)\n",
    "\n",
    "# Display the DataFrame to see its structure\n",
    "df.show()\n",
    "\n",
    "# Collect AlbumId as a list\n",
    "artists_ids = df.select(\"ArtistId\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e851ab2-ab11-4d73-ac54-fd51fe292e03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#OLD WITH NEW EXEPTION HANDLING\n",
    "\n",
    "start_index = artists_id_index\n",
    "current_index = start_index  # Initialize current_index\n",
    "\n",
    "# Define custom exception\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message, index, response_code, retry_after=None):\n",
    "        self.message = message\n",
    "        self.index = index\n",
    "        self.response_code = response_code\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "# Function to handle custom exception and retry logic\n",
    "def handle_exception(exception, retry_limit=3):\n",
    "    print(exception.message)\n",
    "    if exception.response_code == 429 and exception.retry_after:\n",
    "        print(f\"Retrying after {exception.retry_after} seconds...\")\n",
    "        time.sleep(exception.retry_after)  # Wait for the suggested time\n",
    "        retry_limit -= 1\n",
    "        if retry_limit > 0:\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "        \n",
    "# Iterate over Artists IDs\n",
    "for artist_id in artists_ids[start_index:]:\n",
    "    search_url = f\"https://api.spotify.com/v1/artists/{artist_id}\"\n",
    "    retries = 3  # Number of retries\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            result = requests.get(search_url, headers=headers)\n",
    "            response_code = result.status_code  # Capture the response code\n",
    "            print(result)\n",
    "            print(response_code)\n",
    "            \n",
    "            if response_code == 200:\n",
    "                artist = json.loads(result.content)\n",
    "                print(artist)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                #Save album tracks to a JSON file in /mnt/incoming-tracks\n",
    "                filename =f\"/dbfs/mnt/incoming-artist/{artist_id}_incoming-artist_{timestamp}.json\"\n",
    "                with open(filename, 'w') as json_file:\n",
    "                    json.dump(artist, json_file, indent=2)\n",
    "                current_index += 1\n",
    "                break\n",
    "        except CustomException as e:\n",
    "            if not handle_exception(e):\n",
    "                break  # Break the loop if not retrying\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            break  # Break the loop on unexpected errors\n",
    "        retries -= 1\n",
    "\n",
    "\n",
    "dbutils.notebook.exit(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest Artist",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
