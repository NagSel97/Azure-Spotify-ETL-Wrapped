{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096c7361-1f82-4488-a52b-b83ba97c9478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime  # Import the datetime module\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01fd4cc9-1ae5-40c2-9333-7ca586fad5b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'Authorization': 'Bearer BQBGwP4bwiX1ZASQKUtZXPDfNgez8ptnSmF_Krpt24udcu7wXSvL5kFXy5hU1pGvzWrjAXj7f3yJnDcU5Iu_bgtfT9YnJQA5VwP-vxhPWrgi8NYozpU'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|             AlbumId|\n+--------------------+\n|0016pJfQZkCAgume9...|\n|01mEHo9UjwDqzRQX6...|\n|01NYsYQeq6QYBVEjb...|\n|04dX0gE7rgTnvrZC2...|\n|052mfH7QlMsxnrx34...|\n|05jU4HqC6CTnRuP1e...|\n|05sVssLlubTOwlcp2...|\n|08G3mGQXuHItbbsFA...|\n|093nLQ4H81HusNsFd...|\n|0BsAtQgtYtnVPPs0v...|\n|0BTqEvV72i2j6mY8T...|\n|0c0o6oCdk5RmvmEEE...|\n|0czPRsN8uZZ5o3J8u...|\n|0DUOcMjmHGVLqFkWq...|\n|0eI1brgtdrSyC8CdG...|\n|0eMXd1VtCXCkuGWn9...|\n|0GB6OFRgrSKlAXu8G...|\n|0gTZnvc3F1cHmJTTe...|\n|0HGOJnOv8G5EIWBZn...|\n|0hUmPPMsBJpU4qWB8...|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#token = \"\"\n",
    "\n",
    "token = dbutils.widgets.get('token')\n",
    "albums_id_index = 0\n",
    "headers = {\"Authorization\": token}\n",
    "display(headers) \n",
    "\n",
    "# Assuming you have a CSV file uploaded to Databricks File System (DBFS)\n",
    "csv_file_path = \"/mnt/raw/album_data/ds_albums_ids_raw.csv\"\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = spark.read.csv(csv_file_path, header=True)\n",
    "\n",
    "# Display the DataFrame to see its structure\n",
    "df.show()\n",
    "\n",
    "# Collect AlbumId as a list\n",
    "albums_ids = df.select(\"AlbumId\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1caa705a-d2f9-4287-bcc5-3b139bf0b2fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#OLD WITH NEW EXEPTION HANDLING\n",
    "\n",
    "start_index = albums_id_index\n",
    "current_index = start_index  # Initialize current_index\n",
    "\n",
    "# Define custom exception\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message, index, response_code, retry_after=None):\n",
    "        self.message = message\n",
    "        self.index = index\n",
    "        self.response_code = response_code\n",
    "        self.retry_after = retry_after\n",
    "\n",
    "# Function to handle custom exception and retry logic\n",
    "def handle_exception(exception, retry_limit=3):\n",
    "    print(exception.message)\n",
    "    if exception.response_code == 429 and exception.retry_after:\n",
    "        print(f\"Retrying after {exception.retry_after} seconds...\")\n",
    "        time.sleep(exception.retry_after)  # Wait for the suggested time\n",
    "        retry_limit -= 1\n",
    "        if retry_limit > 0:\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "        \n",
    "# Iterate over tracks IDs\n",
    "for album_id in albums_ids[start_index:]:\n",
    "    search_url = f\"https://api.spotify.com/v1/albums/{album_id}\"\n",
    "    retries = 3  # Number of retries\n",
    "    while retries > 0:\n",
    "        try:\n",
    "            result = requests.get(search_url, headers=headers)\n",
    "            response_code = result.status_code  # Capture the response code\n",
    "            print(result)\n",
    "            print(response_code)\n",
    "            \n",
    "            if response_code == 200:\n",
    "                album = json.loads(result.content)\n",
    "                print(album)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                #Save album tracks to a JSON file in /mnt/incoming-tracks\n",
    "                filename =f\"/dbfs/mnt/incoming-albums/{album_id}_incoming-albums_{timestamp}.json\"\n",
    "                with open(filename, 'w') as json_file:\n",
    "                    json.dump(album, json_file, indent=2)\n",
    "                current_index += 1\n",
    "                break\n",
    "        except CustomException as e:\n",
    "            if not handle_exception(e):\n",
    "                break  # Break the loop if not retrying\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            break  # Break the loop on unexpected errors\n",
    "        retries -= 1\n",
    "\n",
    "\n",
    "dbutils.notebook.exit(\"Success\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingest Album",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
