{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "930c51ec-579f-4b4e-a76b-7fb409de6cf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import substring\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6069551-a1f2-485f-b492-7073d7a22e5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n|GenreId|                Name|\n+-------+--------------------+\n|      1|      \"chicago soul\"|\n|      2| \"singer-songwriter\"|\n|      3|       \"korean jazz\"|\n|      4|         \"free jazz\"|\n|      5|       \"electronica\"|\n|      6|\"asian american h...|\n|      7|         \"pop dance\"|\n|      8|     \"neon pop punk\"|\n|      9|      \"classic soul\"|\n|     10| \"post-romantic era\"|\n|     11|         \"kollywood\"|\n|     12|            \"ambeat\"|\n|     13|             \"house\"|\n|     14|     \"rap conscient\"|\n|     15|     \"chicago indie\"|\n|     16|         \"tollywood\"|\n|     17|               \"bgm\"|\n|     18|\"indian undergrou...|\n|     19|\"afro-cuban percu...|\n|     20|       \"pop urbaine\"|\n+-------+--------------------+\nonly showing top 20 rows\n\n+---+--------------------+-------+\n| ID|            ArtistID|GenreID|\n+---+--------------------+-------+\n|  1|3JsMj0DEzyWc0VDlH...|    196|\n|  2|3JsMj0DEzyWc0VDlH...|     50|\n|  3|3JsMj0DEzyWc0VDlH...|    144|\n|  4|3JsMj0DEzyWc0VDlH...|     44|\n|  5|3JsMj0DEzyWc0VDlH...|    109|\n|  6|3JsMj0DEzyWc0VDlH...|    167|\n|  7|3JsMj0DEzyWc0VDlH...|    189|\n|  8|3JsMj0DEzyWc0VDlH...|    155|\n|  9|3JsMj0DEzyWc0VDlH...|    164|\n| 10|3JsMj0DEzyWc0VDlH...|    146|\n| 11|6P7H3ai06vU1sGvdp...|    196|\n| 12|6P7H3ai06vU1sGvdp...|    144|\n| 13|6P7H3ai06vU1sGvdp...|    131|\n| 14|6P7H3ai06vU1sGvdp...|    103|\n| 15|6P7H3ai06vU1sGvdp...|    109|\n| 16|6P7H3ai06vU1sGvdp...|    155|\n| 17|6P7H3ai06vU1sGvdp...|    164|\n| 18|6P7H3ai06vU1sGvdp...|    184|\n| 19|0TF2NxkJZPQoX1H53...|      9|\n| 20|0TF2NxkJZPQoX1H53...|    116|\n+---+--------------------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Exemple de lecture CSV\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Define the schema for the genre DataFrame\n",
    "genre_schema = StructType([\n",
    "    StructField(\"GenreId\", IntegerType(), True),\n",
    "    StructField('Name', StringType(), True)\n",
    "])\n",
    "\n",
    "# Define the schema for the artist genre DataFrame\n",
    "genre_artist_schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"ArtistID\", StringType(), True),\n",
    "    StructField(\"GenreID\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame for each defined schema\n",
    "df_genre = spark.createDataFrame([], schema = genre_schema)\n",
    "df_genre_artist = spark.createDataFrame([], schema = genre_artist_schema)\n",
    "\n",
    "# Read CSV file\n",
    "file_path = '/mnt/raw/genre_data/*.csv'\n",
    "df_csv = spark.read.csv(file_path, header=True)\n",
    "\n",
    "# Get current timestamp\n",
    "start_time = time.time()\n",
    "\n",
    "#df_csv.show()\n",
    "\n",
    "# Need to have the list of distinct genre listened\n",
    "genre_liste = set()\n",
    "\n",
    "artist_genre_count = 0\n",
    "\n",
    "# Iterate over each row in the CSV DataFrame\n",
    "for row in df_csv.rdd.collect():\n",
    "    artistid = str(row['artist_id'])\n",
    "    genre = str(row['genres'])\n",
    "\n",
    "    # I split the genre because it's a list of genre\n",
    "    genre = genre.strip('[]')\n",
    "    elements = genre.split(',')\n",
    "    for elem in elements:\n",
    "        if elem != '':\n",
    "            genre_liste.add(elem.strip())\n",
    "        \n",
    "genre_dicts = {}\n",
    "genre_count = 0\n",
    "\n",
    "# Iterate over each distinct genre\n",
    "for genre in genre_liste:\n",
    "    genre_count += 1\n",
    "\n",
    "    # Create a Spark DataFrame Row\n",
    "    genre_row = Row(GenreId=genre_count, Name=genre)\n",
    "\n",
    "    # Append the Row to the genre DataFrame\n",
    "    df_genre = df_genre.union(spark.createDataFrame([genre_row], schema=genre_schema))\n",
    "\n",
    "    # To defined an id for the genre\n",
    "    genre_dicts[genre] = genre_count\n",
    "\n",
    "\n",
    "# Iterate over each row in the CSV DataFrame\n",
    "for row in df_csv.rdd.collect():\n",
    "    artistid = str(row['artist_id'])\n",
    "    genre = str(row['genres'])\n",
    "    genre = genre.strip('[]')\n",
    "    elements = genre.split(',')\n",
    "    for elem in elements:\n",
    "        if elem != '':\n",
    "            artist_genre_count += 1\n",
    "            \n",
    "            # Create a Spark DataFrame Row\n",
    "            artist_genre_row = Row(ID=artist_genre_count,ArtistID=artistid,GenreID=genre_dicts[elem])\n",
    "\n",
    "            # Append the Row to the genre_artist DataFrame\n",
    "            df_genre_artist = df_genre_artist.union(spark.createDataFrame([artist_genre_row], schema=genre_artist_schema))\n",
    "\n",
    "df_genre.show()\n",
    "df_genre_artist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6710dab3-1c45-4f7c-b828-62d9f7bf3b0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_genre.write.mode(\"overwrite\").csv(\"/mnt/processed/processed-genre\")\n",
    "df_genre_artist.write.mode(\"overwrite\").csv(\"/mnt/processed/processed-genre-artist\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transform Artist Data for Genre",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
